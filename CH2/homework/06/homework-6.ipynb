{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import cross_validation, datasets, metrics, tree \n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите датасет digits с помощью функции load_digits из sklearn.datasets и подготовьте матрицу признаков X и ответы на обучающей выборке y (вам потребуются поля data и target в объекте, который возвращает load_digits).\n",
    "\n",
    "Для оценки качества далее нужно будет использовать cross_val_score из sklearn.cross_validation с параметром cv=10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Мы предлагаем использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел - качество в каждом из k экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score.\n",
    "\n",
    "С небольшой вероятностью вы можете натолкнуться на случай, когда полученное вами качество в каком-то из пунктов не попадет в диапазон, заданный для правильных ответов - в этом случае попробуйте перезапустить ячейку с cross_val_score несколько раз и выбрать наиболее «типичное» значение. Если это не помогает, то где-то была допущена ошибка.\n",
    "\n",
    "Если вам захочется ускорить вычисление cross_val_score - можете попробовать использовать параметр n_jobs, но будьте осторожны: в одной из старых версий sklearn была ошибка, которая приводила к неверному результату работы cross_val_score при задании n_jobs отличным от 1. Сейчас такой проблемы возникнуть не должно, но проверить, что все в порядке, не будет лишним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images', 'data', 'target_names', 'DESCR', 'target']\n"
     ]
    }
   ],
   "source": [
    "data = datasets.load_digits()\n",
    "print data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64) (1797,)\n"
     ]
    }
   ],
   "source": [
    "X = data['data']\n",
    "y = data['target']\n",
    "print X.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 0 7 1 0 6 1 5 4 9 2 7 8 4 6 9 3 7 4 7 1 8 6 0 9 6 1 3 7 5 9 8 3 2 8 8\n",
      " 1 1 0 7 9 0 0 8 7 2 7 4 3 4 3 4 0 4 7 0 5 5 5 2 1 7 0 5 1 8 3 3 4 0 3 7 4\n",
      " 3 4 2 9 7 3 2 5 3 4 1 5 5 2 5 2 2 2 2 7 0 8 1 7 4 2 3 8 2 3 3 0 2 9 9 2 3\n",
      " 2 8 1 1 9 1 2 0 4 8 5 4 4 7 6 7 6 6 1 7 5 6 3 8 3 7 1 8 5 3 4 7 8 5 0 6 0\n",
      " 6 3 7 6 5 6 2 2 2 3 0 7 6 5 6 4 1 0 6 0 6 4 0 9 3 8 1 2 3 1 9 0 7 6 2 9 3\n",
      " 5 3 4 6 3 3 7 4 9 2 7 6 1 6 8 4 0 3 1 0 9 9 9 0 1 8 6 8 0 9 5 9 8 2 3 5 3\n",
      " 0 8 7 4 0 3 3 3 6 3 3 2 9 1 6 9 0 4 2 2 7 9 1 6 7 6 3 7 1 9 3 4 0 6 4 8 5\n",
      " 3 6 3 1 4 0 4 4 8 7 9 1 5 2 7 0 9 0 4 4 0 1 0 6 4 2 8 5 0 2 6 0 1 8 2 0 9\n",
      " 5 6 2 0 5 0 9 1 4 7 1 7 0 6 6 8 0 2 2 6 9 9 7 5 1 7 6 4 6 1 9 4 7 1 3 7 8\n",
      " 1 6 9 8 3 2 4 8 7 5 5 6 9 9 8 5 0 0 4 9 3 0 4 9 4 2 5 4 9 6 4 2 6 0 0 5 6\n",
      " 7 1 9 2 5 1 5 9 8 7 7 0 6 9 3 1 9 3 9 8 7 0 2 3 5 9 2 8 1 9 3 3 0 0 7 3 8\n",
      " 7 9 9 7 1 0 4 5 4 1 7 3 6 5 4 9 0 5 9 1 4 5 0 4 3 4 2 3 9 0 8 7 8 6 9 4 5\n",
      " 7 8 3 7 8 3 2 6 6 7 1 0 8 4 8 9 5 4 1 2 5 3 3 3 5 1 8 7 6 2 3 6 2 5 2 6 4\n",
      " 5 4 4 9 7 9 4 0 2 6 9 3 6 7 3 6 4 7 8 4 1 2 1 1 0 7 3 0 3 2 9 4 5 9 9 4 8\n",
      " 3 3 3 8 4 8 4 5 8 3 9 5 4 7 7 4 0 1 7 9 8 0]\n"
     ]
    }
   ],
   "source": [
    "dtc = tree.DecisionTreeClassifier(random_state=1)\n",
    "# и обучим ее\n",
    "dtc.fit(X, y)\n",
    "predictions = dtc.predict(X)\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_scoring = cross_validation.cross_val_score(dtc,X,y,cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество работы одного решающего дерева обычно получается не очень высоким, но на этом датасете получилось неплохо. Обратите внимание - дерево вполне могло получиться сильно переобученным, ведь мы не ограничивали его глубину. \n",
      "0.83086244395\n"
     ]
    }
   ],
   "source": [
    "print 'Качество работы одного решающего дерева обычно получается не очень высоким, но на этом датасете получилось неплохо. Обратите внимание - дерево вполне могло получиться сильно переобученным, ведь мы не ограничивали его глубину. \\n',tree_scoring.mean()\n",
    "def write_answer_1(ans1):\n",
    "    with open(\"dtc_answer1.txt\", \"w\") as fout:\n",
    "        fout.write(str(ans1))\n",
    "write_answer_1(tree_scoring.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagging = ensemble.BaggingClassifier(dtc,n_estimators=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bagging.fit(X,y)\n",
    "tree_scoring = cross_validation.cross_val_score(bagging,X,y,cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Деревья неустойчивы к изменениям в обучающей выборке, поэтому в результате усреднения по деревьям, построенным на немного разных выборках (как это происходит в бэггинге), получается более точный ответ. \n",
      "0.92100135611\n"
     ]
    }
   ],
   "source": [
    "print 'Деревья неустойчивы к изменениям в обучающей выборке, поэтому в результате усреднения по деревьям, построенным на немного разных выборках (как это происходит в бэггинге), получается более точный ответ. \\n',tree_scoring.mean()\n",
    "def write_answer_2(ans2):\n",
    "    with open(\"dtc_answer2.txt\", \"w\") as fout:\n",
    "        fout.write(str(ans2))\n",
    "write_answer_2(tree_scoring.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С добавлением выбора случайных признаков деревья стали различаться еще больше, в результате композиция работает лучше.\n",
      "0.931563090514\n"
     ]
    }
   ],
   "source": [
    "bagging = ensemble.BaggingClassifier(dtc,n_estimators=100, max_features=8)\n",
    "bagging.fit(X,y)\n",
    "tree_scoring = cross_validation.cross_val_score(bagging,X,y,cv = 10)\n",
    "print 'С добавлением выбора случайных признаков деревья стали различаться еще больше, в результате композиция работает лучше.\\n',tree_scoring.mean()\n",
    "def write_answer_3(ans):\n",
    "    with open(\"dtc_answer3.txt\", \"w\") as fout:\n",
    "        fout.write(str(ans))\n",
    "write_answer_3(tree_scoring.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Если выбирать случайные признаки в каждой вершине, отличия между деревьями становятся еще более существенными, что хорошо сказывается на качестве работы композиции. Именно так и устроен случайный лес.\n",
      "0.949479412423\n"
     ]
    }
   ],
   "source": [
    "dtc = tree.DecisionTreeClassifier(random_state=1, max_features='sqrt')\n",
    "#dtc.fit(X, y)\n",
    "bagging = ensemble.BaggingClassifier(dtc,n_estimators=100)\n",
    "bagging.fit(X,y)\n",
    "tree_scoring = cross_validation.cross_val_score(bagging,X,y,cv = 10)\n",
    "print 'Если выбирать случайные признаки в каждой вершине, отличия между деревьями становятся еще более существенными, что хорошо сказывается на качестве работы композиции. Именно так и устроен случайный лес.\\n', tree_scoring.mean()\n",
    "def write_answer_4(ans):\n",
    "    with open(\"dtc_answer4.txt\", \"w\") as fout:\n",
    "        fout.write(str(ans))\n",
    "write_answer_4(tree_scoring.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.954981125586\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(n_estimators=100,\n",
    "                                      max_depth = None,\n",
    "                                      max_features='sqrt')\n",
    "rfc.fit(X,y)\n",
    "rfc_scorring = cross_validation.cross_val_score(rfc,X,y,cv = 10)\n",
    "print rfc_scorring.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.0944880086238 count trees =  5 mean =  0.891211169835\n",
      "loss =  0.0842050014857 count trees =  10 mean =  0.938058827428\n",
      "loss =  0.0853932691657 count trees =  15 mean =  0.953957140911\n",
      "loss =  0.0888797987185 count trees =  30 mean =  0.96103447369\n",
      "loss =  0.0826289186289 count trees =  70 mean =  0.976176360087\n",
      "loss =  0.0822268086663 count trees =  100 mean =  0.972211931617\n",
      "loss =  0.0827327961715 count trees =  200 mean =  0.972238084893\n",
      "loss =  0.0825486705835 count trees =  500 mean =  0.971360679135\n",
      "loss =  0.0819904477695 count trees =  1000 mean =  0.971424939747\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# производим разбивку данных на обучение и тест с помошью \n",
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(X, \n",
    "                                                                                     y, \n",
    "                                                                                     test_size = 0.3,\n",
    "                                                                                     random_state = 1)\n",
    "n_estimators = [5,10,15,30,70,100,200,500,1000]\n",
    "for n in n_estimators:\n",
    "    rfc = ensemble.RandomForestClassifier(n_estimators=n,\n",
    "                                      max_depth = None,\n",
    "                                      max_features='sqrt')\n",
    "    rfc.fit(X,y)\n",
    "    \n",
    "    prediction = rfc.predict(test_data)\n",
    "    #ras = metrics.roc_auc_score(test_labels,prediction)\n",
    "    #log_loss = metrics.log_loss(test_labels,prediction)\n",
    "    clf_probs = rfc.predict_proba(test_data)\n",
    "    loss = metrics.log_loss(test_labels, clf_probs)\n",
    "    \n",
    "    rfc_scorring = cross_validation.cross_val_score(rfc,train_data,train_labels,cv = 10)\n",
    "    print 'loss = ',loss, 'count trees = ',n,'mean = ',rfc_scorring.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  0.133146957954 count trees =  1 mean =  0.965813963307\n",
      "loss =  0.107295054747 count trees =  3 mean =  0.969811931617\n",
      "loss =  0.100893166995 count trees =  4 mean =  0.970567028341\n",
      "loss =  0.0808499754266 count trees =  8 mean =  0.970637030824\n",
      "loss =  0.0807772440431 count trees =  10 mean =  0.969817987819\n",
      "loss =  0.0765245612959 count trees =  15 mean =  0.968184878\n",
      "loss =  0.0720567263532 count trees =  20 mean =  0.968147964009\n",
      "loss =  0.0643135226745 count trees =  40 mean =  0.956321590708\n",
      "loss =  0.061427971543 count trees =  60 mean =  0.945964544187\n"
     ]
    }
   ],
   "source": [
    "n_features = [1,3,4,8,10,15,20,40,60]\n",
    "for n in n_features:\n",
    "    rfc = ensemble.RandomForestClassifier(n_estimators=100,\n",
    "                                      max_depth = None,\n",
    "                                      max_features= n)\n",
    "    rfc.fit(X,y)\n",
    "    \n",
    "    prediction = rfc.predict(test_data)\n",
    "    #ras = metrics.roc_auc_score(test_labels,prediction)\n",
    "    #log_loss = metrics.log_loss(test_labels,prediction)\n",
    "    clf_probs = rfc.predict_proba(test_data)\n",
    "    loss = metrics.log_loss(test_labels, clf_probs)\n",
    "    \n",
    "    rfc_scorring = cross_validation.cross_val_score(rfc,train_data,train_labels,cv = 10)\n",
    "    print 'loss = ',loss, 'count trees = ',n,'mean = ',rfc_scorring.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  1.88783770021 count trees =  1 mean =  0.742339527098\n",
      "loss =  1.11463607172 count trees =  3 mean =  0.878262343293\n",
      "loss =  0.840697002991 count trees =  4 mean =  0.914287344953\n",
      "loss =  0.208531038806 count trees =  8 mean =  0.967371267148\n",
      "loss =  0.117381777531 count trees =  10 mean =  0.971519145709\n",
      "loss =  0.0827138095209 count trees =  15 mean =  0.969855487819\n",
      "loss =  0.0815562864162 count trees =  20 mean =  0.963423419971\n",
      "loss =  0.0811652351766 count trees =  40 mean =  0.969803628\n",
      "loss =  0.0805472583519 count trees =  60 mean =  0.969802732273\n"
     ]
    }
   ],
   "source": [
    "n_depth = [1,3,5,10,20,40,60,200]\n",
    "for n in n_features:\n",
    "    rfc = ensemble.RandomForestClassifier(n_estimators=100,\n",
    "                                      max_depth = n,\n",
    "                                      max_features= 'sqrt')\n",
    "    rfc.fit(X,y)\n",
    "    \n",
    "    prediction = rfc.predict(test_data)\n",
    "    #ras = metrics.roc_auc_score(test_labels,prediction)\n",
    "    #log_loss = metrics.log_loss(test_labels,prediction)\n",
    "    clf_probs = rfc.predict_proba(test_data)\n",
    "    loss = metrics.log_loss(test_labels, clf_probs)\n",
    "    \n",
    "    rfc_scorring = cross_validation.cross_val_score(rfc,train_data,train_labels,cv = 10)\n",
    "    print 'loss = ',loss, 'count trees = ',n,'mean = ',rfc_scorring.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2, 3, 5, 7\n",
    "\n",
    "def write_answer_5(a1,a2,a3,a4):\n",
    "    answers = [a1, a2, a3, a4]\n",
    "    with open(\"dtc_answer5.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(num) for num in answers]))\n",
    "        \n",
    "write_answer_5(2,3,4,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
