{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\frac{1}{\\ell}\\sum_{i=1}^\\ell{{(y_i - (w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}))}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$w_0 \\leftarrow w_0 + \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{(y_i - (w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}))}}$$\n",
    "$$w_j \\leftarrow w_j + \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}(y_i - (w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}))}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "У градиентного спуска, описанного выше, есть один недостаток. На больших выборках вычисление градиента по всем имеющимся данным на каждом шаге может быть вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$w_0 \\leftarrow w_0 + \\frac{2\\eta}{\\ell} {(y_k - (w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}))}$$\n",
    "$$w_j \\leftarrow w_j + \\frac{2\\eta}{\\ell} {x_{kj}(y_k - (w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}))},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, соответствующий целевому признаку, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Ваш код здесь\n",
    "adver_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ваш код здесь\n",
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = adver_data[['TV','Radio','Newspaper']].values #Ваш код здесь\n",
    "y = adver_data['Sales'].values #Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> [ 147.0425   23.264    30.554 ] [ 85.63933176  14.80964564  21.72410606]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "means, stds = X.mean(axis=0), X.std(axis=0) #X.std(axis=0) Ваш код здесь - стандартное отклонение по кажд.столбцу или матрицы?\n",
    "print type(stds),means,stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = (X-means)/stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   9.69852266e-01   9.81522472e-01   1.77894547e+00]\n",
      " [  1.00000000e+00  -1.19737623e+00   1.08280781e+00   6.69578760e-01]\n",
      " [  1.00000000e+00  -1.51615499e+00   1.52846331e+00   1.78354865e+00]\n",
      " [  1.00000000e+00   5.20496822e-02   1.21785493e+00   1.28640506e+00]\n",
      " [  1.00000000e+00   3.94182198e-01  -8.41613655e-01   1.28180188e+00]\n",
      " [  1.00000000e+00  -1.61540845e+00   1.73103399e+00   2.04592999e+00]\n",
      " [  1.00000000e+00  -1.04557682e+00   6.43904671e-01  -3.24708413e-01]\n",
      " [  1.00000000e+00  -3.13436589e-01  -2.47406325e-01  -8.72486994e-01]\n",
      " [  1.00000000e+00  -1.61657614e+00  -1.42906863e+00  -1.36042422e+00]\n",
      " [  1.00000000e+00   6.16042873e-01  -1.39530685e+00  -4.30581584e-01]\n",
      " [  1.00000000e+00  -9.45155670e-01  -1.17923146e+00  -2.92486143e-01]\n",
      " [  1.00000000e+00   7.90028350e-01   4.96973404e-02  -1.22232878e+00]\n",
      " [  1.00000000e+00  -1.43908760e+00   7.99208859e-01   1.62704048e+00]\n",
      " [  1.00000000e+00  -5.78501712e-01  -1.05768905e+00  -1.07502697e+00]\n",
      " [  1.00000000e+00   6.66253447e-01   6.50657027e-01   7.11007392e-01]\n",
      " [  1.00000000e+00   5.64664612e-01   1.65000572e+00   1.02862691e+00]\n",
      " [  1.00000000e+00  -9.25304978e-01   9.00494200e-01   3.84117072e+00]\n",
      " [  1.00000000e+00   1.56887609e+00   1.10306488e+00   1.16211917e+00]\n",
      " [  1.00000000e+00  -9.08957349e-01  -1.86635121e-01  -5.64073843e-01]\n",
      " [  1.00000000e+00   3.00679600e-03   4.29449843e-02  -5.27248393e-01]\n",
      " [  1.00000000e+00   8.33232798e-01   2.99534513e-01   1.05164281e+00]\n",
      " [  1.00000000e+00   1.05509347e+00  -1.22649795e+00  -3.24708413e-01]\n",
      " [  1.00000000e+00  -1.56286250e+00  -4.97243498e-01   8.76721921e-01]\n",
      " [  1.00000000e+00   9.48833887e-01  -4.29719938e-01  -2.00422516e-01]\n",
      " [  1.00000000e+00  -9.89527805e-01  -7.20071247e-01  -5.64073843e-01]\n",
      " [  1.00000000e+00   1.35285385e+00  -1.33453565e+00  -5.08835667e-01]\n",
      " [  1.00000000e+00  -4.83714657e-02   4.07572210e-01  -8.26455181e-01]\n",
      " [  1.00000000e+00   1.08662104e+00  -4.43224650e-01  -3.52327501e-01]\n",
      " [  1.00000000e+00   1.18820988e+00   2.59020377e-01  -3.52327501e-01]\n",
      " [  1.00000000e+00  -8.92609721e-01  -4.90491142e-01   4.71641962e-01]\n",
      " [  1.00000000e+00   1.70316018e+00   3.40048650e-01   5.82118314e-01]\n",
      " [  1.00000000e+00  -3.98677796e-01  -3.95958157e-01   3.70371972e-01]\n",
      " [  1.00000000e+00  -5.82004775e-01  -1.46958277e+00  -2.55016247e-02]\n",
      " [  1.00000000e+00   1.38438142e+00  -2.20396901e-01  -1.39264649e+00]\n",
      " [  1.00000000e+00  -5.99520091e-01  -1.47633512e+00  -1.06582061e+00]\n",
      " [  1.00000000e+00   1.67747105e+00  -1.29402151e+00  -1.01518562e+00]\n",
      " [  1.00000000e+00   1.39956136e+00   1.38666383e+00  -1.17629696e+00]\n",
      " [  1.00000000e+00  -8.44734522e-01   1.76479577e+00   6.97197848e-01]\n",
      " [  1.00000000e+00  -1.21372386e+00   2.32010953e-01   2.09260624e-01]\n",
      " [  1.00000000e+00   9.45330823e-01   9.74770116e-01   6.65620024e-02]\n",
      " [  1.00000000e+00   6.47570443e-01  -6.50927121e-02   4.81492770e-02]\n",
      " [  1.00000000e+00   3.49810063e-01   6.84418807e-01   3.74975153e-01]\n",
      " [  1.00000000e+00   1.71133400e+00   2.99534513e-01  -1.32359877e+00]\n",
      " [  1.00000000e+00   6.98948705e-01  -1.00367020e+00  -1.91216154e-01]\n",
      " [  1.00000000e+00  -1.42390765e+00   1.64487393e-01   5.86721496e-01]\n",
      " [  1.00000000e+00   3.27623995e-01  -5.15880000e-02   4.35460956e-02]\n",
      " [  1.00000000e+00  -6.69581357e-01  -9.02384859e-01   2.36879713e-01]\n",
      " [  1.00000000e+00   1.08428567e+00   1.23135965e+00  -5.54867481e-01]\n",
      " [  1.00000000e+00   9.35989321e-01  -5.03995854e-01   8.90531465e-01]\n",
      " [  1.00000000e+00  -9.35814168e-01  -7.80842451e-01   2.87514708e-01]\n",
      " [  1.00000000e+00   6.16042873e-01  -1.36154507e+00   1.86244718e-01]\n",
      " [  1.00000000e+00  -5.44638766e-01  -9.22641928e-01  -1.24074150e+00]\n",
      " [  1.00000000e+00   8.09879042e-01   1.24486436e+00   4.16403786e-01]\n",
      " [  1.00000000e+00   4.15200577e-01   1.54872038e+00   1.29561142e+00]\n",
      " [  1.00000000e+00   1.35051848e+00   3.73810430e-01  -6.74550196e-01]\n",
      " [  1.00000000e+00   6.05533683e-01   1.76479577e+00   1.35545278e+00]\n",
      " [  1.00000000e+00  -1.63175608e+00   3.26543937e-01   4.99261050e-01]\n",
      " [  1.00000000e+00  -1.26606546e-01  -2.74415749e-01  -6.42327927e-01]\n",
      " [  1.00000000e+00   7.44488528e-01   1.77830048e+00   3.28943340e-01]\n",
      " [  1.00000000e+00   7.43320840e-01   4.21076922e-01  -9.78360166e-01]\n",
      " [  1.00000000e+00  -1.09228433e+00  -1.43582099e+00  -4.21375221e-01]\n",
      " [  1.00000000e+00   1.33417085e+00   1.31238792e+00   1.11148417e+00]\n",
      " [  1.00000000e+00   1.07727954e+00  -5.24252922e-01  -1.49787521e-01]\n",
      " [  1.00000000e+00  -5.17781948e-01   4.27829278e-01  -1.01978880e+00]\n",
      " [  1.00000000e+00  -1.86158622e-01   1.31914027e+00  -7.61366196e-02]\n",
      " [  1.00000000e+00  -9.11292725e-01  -9.42898996e-01  -1.36502740e+00]\n",
      " [  1.00000000e+00  -1.34917564e+00   9.02114765e-02  -1.30518604e+00]\n",
      " [  1.00000000e+00  -9.04082253e-02  -5.91776482e-01  -9.36931533e-01]\n",
      " [  1.00000000e+00   1.05509347e+00   2.86029801e-01  -9.00106083e-01]\n",
      " [  1.00000000e+00   8.14549794e-01   1.39341619e+00  -1.54390703e-01]\n",
      " [  1.00000000e+00   6.07869059e-01   4.95352838e-01   3.74975153e-01]\n",
      " [  1.00000000e+00  -4.34876116e-01  -6.05281194e-01   5.27524584e-02]\n",
      " [  1.00000000e+00  -1.40405696e+00   6.57409383e-01  -5.18042030e-01]\n",
      " [  1.00000000e+00  -2.06009314e-01  -1.18598381e+00   3.43397329e-02]\n",
      " [  1.00000000e+00   7.74848409e-01   9.02114765e-02  -8.03439274e-01]\n",
      " [  1.00000000e+00  -1.51965805e+00   1.37991148e+00   2.70878810e+00]\n",
      " [  1.00000000e+00  -1.39588315e+00  -1.46283041e+00  -4.53597491e-01]\n",
      " [  1.00000000e+00  -3.09933525e-01   3.53553362e-01  -7.52804279e-01]\n",
      " [  1.00000000e+00  -1.65394214e+00   4.48086346e-01  -9.73756984e-01]\n",
      " [  1.00000000e+00  -3.62479475e-01  -1.05093669e+00  -3.43121138e-01]\n",
      " [  1.00000000e+00  -8.24883830e-01   2.32010953e-01  -3.79946589e-01]\n",
      " [  1.00000000e+00   1.08311798e+00  -1.29402151e+00   2.92117889e-01]\n",
      " [  1.00000000e+00  -8.37728396e-01  -2.00139833e-01   8.95779092e-02]\n",
      " [  1.00000000e+00  -9.18298852e-01   1.43393033e+00   2.32276531e-01]\n",
      " [  1.00000000e+00   7.76016097e-01   1.33264499e+00   1.49419267e-01]\n",
      " [  1.00000000e+00   5.38975481e-01  -3.28434597e-01   1.61783412e+00]\n",
      " [  1.00000000e+00  -8.26051518e-01   2.86029801e-01  -6.69947015e-01]\n",
      " [  1.00000000e+00  -4.24366926e-01   1.17058844e+00   1.50275459e+00]\n",
      " [  1.00000000e+00  -6.85928986e-01   1.50982681e-01   1.97227908e+00]\n",
      " [  1.00000000e+00  -4.34876116e-01   1.65675807e+00   9.59579186e-01]\n",
      " [  1.00000000e+00  -1.48792614e-01  -1.24000266e+00  -9.78360166e-01]\n",
      " [  1.00000000e+00  -1.38303858e+00  -1.46958277e+00   1.12593816e-01]\n",
      " [  1.00000000e+00   8.25058983e-01   6.91171163e-01   1.30942097e+00]\n",
      " [  1.00000000e+00   1.21273132e+00   8.93741844e-01   1.92164409e+00]\n",
      " [  1.00000000e+00  -4.62900623e-01  -6.25538262e-01  -9.04709264e-01]\n",
      " [  1.00000000e+00   1.89836839e-01   5.62876398e-01   1.02862691e+00]\n",
      " [  1.00000000e+00   5.90353742e-01  -1.33453565e+00  -1.13486833e+00]\n",
      " [  1.00000000e+00   4.42057396e-01  -1.52873340e-01  -3.93756133e-01]\n",
      " [  1.00000000e+00   1.66579418e+00   1.28537849e+00   9.50372823e-01]\n",
      " [  1.00000000e+00  -1.38283424e-01   1.24486436e+00   7.06404211e-01]\n",
      " [  1.00000000e+00   8.79940308e-01  -1.28051680e+00   8.85928284e-01]\n",
      " [  1.00000000e+00   1.74402926e+00   8.80237132e-01   3.23815396e+00]\n",
      " [  1.00000000e+00   1.55486384e+00  -8.88880147e-01  -4.21375221e-01]\n",
      " [  1.00000000e+00   4.77088029e-01  -4.09462869e-01  -5.82486569e-01]\n",
      " [  1.00000000e+00   1.06443498e+00   7.45190011e-01  -1.16248742e+00]\n",
      " [  1.00000000e+00  -1.06755854e-01   1.56222509e+00   1.30942097e+00]\n",
      " [  1.00000000e+00  -1.42507534e+00  -8.28108943e-01  -3.93111688e-02]\n",
      " [  1.00000000e+00  -6.61407543e-01  -1.55061104e+00  -3.38517957e-01]\n",
      " [  1.00000000e+00  -1.56403019e+00  -1.54385868e+00  -2.28041604e-01]\n",
      " [  1.00000000e+00   1.26527727e+00   2.45515665e-01  -1.15328106e+00]\n",
      " [  1.00000000e+00   9.19641692e-01  -1.01717491e+00   1.19434143e+00]\n",
      " [  1.00000000e+00   1.10530405e+00   9.95027184e-01  -3.38517957e-01]\n",
      " [  1.00000000e+00   3.34630122e-01  -5.31005278e-01  -1.29597968e+00]\n",
      " [  1.00000000e+00   7.30476274e-01  -1.79882765e-01  -9.13915627e-01]\n",
      " [  1.00000000e+00  -8.03865450e-01   1.58923451e+00   1.81641536e-01]\n",
      " [  1.00000000e+00  -8.40063771e-01   7.92456503e-01   1.01942054e+00]\n",
      " [  1.00000000e+00  -9.15759131e-02  -6.05281194e-01  -2.28041604e-01]\n",
      " [  1.00000000e+00  -8.24883830e-01  -1.51684926e+00  -7.25185191e-01]\n",
      " [  1.00000000e+00  -2.49213762e-01   9.20751268e-01   2.23926360e+00]\n",
      " [  1.00000000e+00  -1.49046586e+00  -4.90491142e-01  -3.79946589e-01]\n",
      " [  1.00000000e+00  -6.70544700e-02   2.38763309e-01   7.20213755e-01]\n",
      " [  1.00000000e+00  -1.49747198e+00  -1.05606848e-01   9.13547372e-01]\n",
      " [  1.00000000e+00   8.98623313e-01  -1.40881156e+00  -6.88359740e-01]\n",
      " [  1.00000000e+00  -2.79573643e-01   7.65447079e-01  -8.35661544e-01]\n",
      " [  1.00000000e+00   9.62846140e-01   6.10142891e-01   2.00910454e+00]\n",
      " [  1.00000000e+00  -6.98773552e-01  -7.74090095e-01  -2.14232060e-01]\n",
      " [  1.00000000e+00  -1.62591764e+00   1.05579839e+00   9.22753735e-01]\n",
      " [  1.00000000e+00  -7.80511695e-01  -1.57086811e+00  -9.82963347e-01]\n",
      " [  1.00000000e+00   8.55418865e-01   1.73778635e+00  -1.25915423e+00]\n",
      " [  1.00000000e+00  -1.02105537e+00  -7.60585383e-01   5.77515133e-01]\n",
      " [  1.00000000e+00  -1.70882347e+00   1.10306488e+00  -1.00597925e+00]\n",
      " [  1.00000000e+00   1.37971067e+00  -1.37504978e+00   5.72911952e-01]\n",
      " [  1.00000000e+00  -1.61891151e+00   2.65772733e-01  -1.30978922e+00]\n",
      " [  1.00000000e+00   8.49580427e-01   6.91171163e-01   6.69578760e-01]\n",
      " [  1.00000000e+00  -1.28612050e+00   1.03554132e+00   1.61323094e+00]\n",
      " [  1.00000000e+00  -1.15300409e+00   1.60273923e+00  -1.01518562e+00]\n",
      " [  1.00000000e+00  -1.41806922e+00   1.06255074e+00  -9.78360166e-01]\n",
      " [  1.00000000e+00   1.47896413e+00   3.80562786e-01   1.34164324e+00]\n",
      " [  1.00000000e+00  -1.21489154e+00   1.77992105e-01  -4.62803854e-01]\n",
      " [  1.00000000e+00   4.42057396e-01   1.39341619e+00  -1.32820195e+00]\n",
      " [  1.00000000e+00  -8.59914463e-01  -4.22967582e-01  -8.12645637e-01]\n",
      " [  1.00000000e+00   5.44813920e-01   8.19465927e-01   2.07354907e+00]\n",
      " [  1.00000000e+00   8.57754241e-01   6.70914095e-01   3.38149702e-01]\n",
      " [  1.00000000e+00  -4.95595880e-01  -1.18598381e+00   1.77038355e-01]\n",
      " [  1.00000000e+00  -5.93681653e-01  -5.71519414e-01   3.84181516e-01]\n",
      " [  1.00000000e+00  -7.87313476e-02  -1.44257334e+00  -9.92169710e-01]\n",
      " [  1.00000000e+00   1.08662104e+00  -1.07794612e+00  -1.00597925e+00]\n",
      " [  1.00000000e+00   1.12281936e+00   1.73778635e+00   6.32753309e-01]\n",
      " [  1.00000000e+00  -1.27327593e+00   1.15033137e+00  -8.58677450e-01]\n",
      " [  1.00000000e+00  -1.19504085e+00   1.71239749e-01  -4.58200672e-01]\n",
      " [  1.00000000e+00   1.56070228e+00  -6.32290618e-01   2.96721070e-01]\n",
      " [  1.00000000e+00  -3.04095087e-01  -1.00367020e+00   8.35293289e-01]\n",
      " [  1.00000000e+00   5.90353742e-01   2.43084817e-03  -7.52804279e-01]\n",
      " [  1.00000000e+00   2.83251860e-01   1.10981724e+00   3.28943340e-01]\n",
      " [  1.00000000e+00   4.75920341e-01  -1.46120984e-01  -9.69153803e-01]\n",
      " [  1.00000000e+00  -1.66912209e+00  -7.87594807e-01  -1.14407469e+00]\n",
      " [  1.00000000e+00  -6.20538471e-01   1.36640677e+00   9.18150553e-01]\n",
      " [  1.00000000e+00   3.21989902e-02  -1.48308748e+00  -2.87882962e-01]\n",
      " [  1.00000000e+00  -1.58037782e+00   9.20751268e-01   6.74181942e-01]\n",
      " [  1.00000000e+00  -1.79152496e-01  -3.28434597e-01   1.86244718e-01]\n",
      " [  1.00000000e+00   2.97264113e-01  -3.48691665e-01   6.72064478e-03]\n",
      " [  1.00000000e+00  -7.16288868e-01   8.46475352e-01   8.62912377e-01]\n",
      " [  1.00000000e+00   4.82926468e-01  -3.48691665e-01  -2.28041604e-01]\n",
      " [  1.00000000e+00   1.92172214e-01   9.13998912e-01  -1.06582061e+00]\n",
      " [  1.00000000e+00  -3.48467222e-01  -5.78271770e-01  -1.15788424e+00]\n",
      " [  1.00000000e+00   1.02123053e+00  -1.34128800e+00   2.49704176e+00]\n",
      " [  1.00000000e+00  -1.50798117e+00   9.68017760e-01  -4.12168859e-01]\n",
      " [  1.00000000e+00   6.97781017e-01  -1.21974559e+00  -5.13438849e-01]\n",
      " [  1.00000000e+00   7.98202165e-01   2.26879163e-02   1.24497643e+00]\n",
      " [  1.00000000e+00   1.60273904e+00  -8.55118367e-01  -1.11185242e+00]\n",
      " [  1.00000000e+00  -1.13315340e+00  -7.87594807e-01  -5.59470662e-01]\n",
      " [  1.00000000e+00   2.03849092e-01  -1.59625696e-01   7.75451931e-01]\n",
      " [  1.00000000e+00  -1.48813048e+00  -2.13644545e-01  -6.23915201e-01]\n",
      " [  1.00000000e+00   2.49388915e-01  -1.09145083e+00  -8.17248818e-01]\n",
      " [  1.00000000e+00   8.79940308e-01  -1.34128800e+00  -8.03439274e-01]\n",
      " [  1.00000000e+00   1.51633014e+00   1.73103399e+00   5.17673775e-01]\n",
      " [  1.00000000e+00   1.18353913e+00   4.68343414e-01  -4.72010216e-01]\n",
      " [  1.00000000e+00   2.70407294e-01  -1.04418434e+00   2.13863806e-01]\n",
      " [  1.00000000e+00   1.51399477e+00  -1.41556392e+00  -3.15502050e-01]\n",
      " [  1.00000000e+00   2.16693657e-01  -8.95632503e-01  -5.96296113e-01]\n",
      " [  1.00000000e+00   1.11601758e-01  -1.39530685e+00  -1.02439198e+00]\n",
      " [  1.00000000e+00   8.34400486e-01  -1.20624088e+00  -1.45184340e-01]\n",
      " [  1.00000000e+00  -1.06075676e+00  -1.18598381e+00  -3.93111688e-02]\n",
      " [  1.00000000e+00   1.64127273e+00   1.33264499e+00   1.89862818e+00]\n",
      " [  1.00000000e+00   1.24659427e+00  -1.32616272e-01  -2.55016247e-02]\n",
      " [  1.00000000e+00   6.76762637e-01   1.47444446e+00  -5.04232486e-01]\n",
      " [  1.00000000e+00  -8.80728498e-02  -1.42906863e+00  -1.82009791e-01]\n",
      " [  1.00000000e+00   5.14454038e-01   3.67058074e-01  -5.68677025e-01]\n",
      " [  1.00000000e+00   1.62258973e+00  -6.32290618e-01  -1.23613832e+00]\n",
      " [  1.00000000e+00  -1.49863967e+00  -7.53833027e-01  -3.29311594e-01]\n",
      " [  1.00000000e+00  -1.25576062e+00   1.20435022e+00  -1.13947151e+00]\n",
      " [  1.00000000e+00  -8.35393020e-01  -8.41613655e-01  -1.13026515e+00]\n",
      " [  1.00000000e+00  -1.51615499e+00  -1.29402151e+00   4.81492770e-02]\n",
      " [  1.00000000e+00   2.30705910e-01   1.26512143e+00  -1.24074150e+00]\n",
      " [  1.00000000e+00   3.10313024e-02   8.32970639e-01  -1.13026515e+00]\n",
      " [  1.00000000e+00  -1.27094056e+00  -1.32103093e+00  -7.71217005e-01]\n",
      " [  1.00000000e+00  -6.17035408e-01  -1.24000266e+00  -1.03359834e+00]\n",
      " [  1.00000000e+00   3.49810063e-01  -9.42898996e-01  -1.11185242e+00]\n",
      " [  1.00000000e+00   1.59456522e+00   1.26512143e+00   1.64085003e+00]\n",
      " [  1.00000000e+00   9.93206022e-01  -9.90165488e-01  -1.00597925e+00]]\n"
     ]
    }
   ],
   "source": [
    "#X = np.hstack((X,np.ones(X.shape[0]).reshape((-1,1))))# Ваш код здесь\n",
    "X = np.hstack((np.ones(X.shape[0]).reshape(X.shape[0],1),X))\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return sum((yt-yp)** 2 for yt,yp in zip(y, y_pred))/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "ymed=np.full(len(y),np.median(y))\n",
    "answer1 = mserror(y,ymed)\n",
    "print answer1\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot(np.dot(np.linalg.inv(np.dot(X.T,X)),X.T),y)\n",
    "    # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.0225       3.91925365   2.79206274  -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print norm_eq_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot([1,0.0,0.0,0.0],norm_eq_weights)\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w)# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y,linear_prediction(X,norm_eq_weights))# Ваш код здесь\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    l=len(X)\n",
    "    return w+(2*eta*X[train_ind]/l)*(y[train_ind]-sum((xi*wi) for xi,wi in zip(X[train_ind],w)))\n",
    "# Ваш код здесь\n",
    "# X, y и w - объекты типа nparray(ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        w_curr=stochastic_gradient_step(X,y,w,random_ind,eta)\n",
    "        \n",
    "        weight_dist=np.linalg.norm(w_curr-w,ord=1)\n",
    "        err_curr=mserror(y,np.dot(X,w_curr))\n",
    "        errors.append(err_curr)\n",
    "        \n",
    "        if (verbose == True):\n",
    "            if (iter_num%500) == 0:\n",
    "                print \"iter \"+str(iter_num)+\" weight_dist \"+str(weight_dist)+\" w_curr \"+str(w_curr)\n",
    "        iter_num+=1\n",
    "        w=w_curr\n",
    "        # Ваш код здесь\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 weight_dist 0.00572037642507 w_curr [ 0.00148     0.0023012  -0.00131554 -0.00062364]\n",
      "iter 500 weight_dist 0.00672615147244 w_curr [ 0.70322323  0.23473488  0.15581764  0.0438029 ]\n",
      "iter 1000 weight_dist 0.00374320659878 w_curr [ 1.34304318  0.40179329  0.23862427  0.07572638]\n",
      "iter 1500 weight_dist 0.00402184403623 w_curr [ 1.9686609   0.59669789  0.35797296  0.12590129]\n",
      "iter 2000 weight_dist 0.00239457150481 w_curr [ 2.55403025  0.76693119  0.48017239  0.20819563]\n",
      "iter 2500 weight_dist 0.0037035837487 w_curr [ 3.12480775  0.95852832  0.61155333  0.25833903]\n",
      "iter 3000 weight_dist 0.00486158400956 w_curr [ 3.6394326   1.02966045  0.67298462  0.25087833]\n",
      "iter 3500 weight_dist 0.00387845447004 w_curr [ 4.13314851  1.14962693  0.74351981  0.27862258]\n",
      "iter 4000 weight_dist 0.0105532237373 w_curr [ 4.60786672  1.2693082   0.82388981  0.27745868]\n",
      "iter 4500 weight_dist 0.00272339552055 w_curr [ 5.07456461  1.40993189  0.9585552   0.37284675]\n",
      "iter 5000 weight_dist 0.00154417727562 w_curr [ 5.50931906  1.53611144  1.06385641  0.37234577]\n",
      "iter 5500 weight_dist 0.0024404300241 w_curr [ 5.91962019  1.64971706  1.15004954  0.36404098]\n",
      "iter 6000 weight_dist 0.00359281151399 w_curr [ 6.31493451  1.77778228  1.25198374  0.4072943 ]\n",
      "iter 6500 weight_dist 0.00166139949287 w_curr [ 6.68991761  1.85928015  1.32229571  0.4134247 ]\n",
      "iter 7000 weight_dist 0.00163091390304 w_curr [ 7.04354544  1.95557001  1.36273252  0.42151556]\n",
      "iter 7500 weight_dist 0.00203958052732 w_curr [ 7.38870361  2.0649795   1.4445245   0.44355056]\n",
      "iter 8000 weight_dist 0.00363934909826 w_curr [ 7.7054803   2.14355074  1.50609817  0.45344162]\n",
      "iter 8500 weight_dist 0.00115545162038 w_curr [ 8.0131999   2.24884911  1.5545793   0.43658584]\n",
      "iter 9000 weight_dist 0.00230583194583 w_curr [ 8.31020158  2.34348462  1.62754088  0.44931526]\n",
      "iter 9500 weight_dist 0.00243391155024 w_curr [ 8.58238545  2.42134534  1.6683421   0.4365977 ]\n",
      "iter 10000 weight_dist 0.00169797196445 w_curr [ 8.84320053  2.48856541  1.71380822  0.43205973]\n",
      "iter 10500 weight_dist 0.00314069860895 w_curr [ 9.09781759  2.56806717  1.77634096  0.42792614]\n",
      "iter 11000 weight_dist 0.00159722941093 w_curr [ 9.35313253  2.65371724  1.84980854  0.43130547]\n",
      "iter 11500 weight_dist 0.0018733858163 w_curr [ 9.5711242   2.7079411   1.87993089  0.43766425]\n",
      "iter 12000 weight_dist 0.00171980387521 w_curr [ 9.78380118  2.75060854  1.89360179  0.44225233]\n",
      "iter 12500 weight_dist 0.00157639376488 w_curr [ 9.99318012  2.81260545  1.92393706  0.44950458]\n",
      "iter 13000 weight_dist 0.00459330528463 w_curr [ 10.19169772   2.87840492   1.96234937   0.44999768]\n",
      "iter 13500 weight_dist 0.000874109364726 w_curr [ 10.37461379   2.92982491   1.98481511   0.4521333 ]\n",
      "iter 14000 weight_dist 0.00122235834943 w_curr [ 10.55692553   2.96471084   2.01374727   0.43876693]\n",
      "iter 14500 weight_dist 0.000762423059014 w_curr [ 10.73280578   3.02010154   2.05861498   0.43205821]\n",
      "iter 15000 weight_dist 0.00151595608155 w_curr [ 10.89341854   3.07022521   2.10738658   0.42448162]\n",
      "iter 15500 weight_dist 0.000288564158991 w_curr [ 11.03790724   3.10175808   2.13015974   0.41793911]\n",
      "iter 16000 weight_dist 0.00200429886582 w_curr [ 11.18670314   3.13449625   2.15325401   0.40571829]\n",
      "iter 16500 weight_dist 0.000597088473947 w_curr [ 11.32038965   3.16673688   2.17616332   0.40488196]\n",
      "iter 17000 weight_dist 0.00107587281353 w_curr [ 11.45494308   3.20868924   2.2107353    0.39371644]\n",
      "iter 17500 weight_dist 0.00049091163532 w_curr [ 11.57752573   3.24482257   2.23241244   0.38543308]\n",
      "iter 18000 weight_dist 0.00140852595182 w_curr [ 11.69191995   3.2829311    2.25874154   0.37420175]\n",
      "iter 18500 weight_dist 0.000950711325393 w_curr [ 11.80635187   3.31919635   2.28210688   0.36792761]\n",
      "iter 19000 weight_dist 0.00191415106226 w_curr [ 11.91484667   3.34665844   2.30056608   0.35820682]\n",
      "iter 19500 weight_dist 0.000484490704848 w_curr [ 12.01148819   3.37640469   2.32429564   0.34874252]\n",
      "iter 20000 weight_dist 0.00101185820653 w_curr [ 12.10485845   3.39926643   2.33498149   0.3437401 ]\n",
      "iter 20500 weight_dist 0.000642481045885 w_curr [ 12.19902537   3.43560288   2.35794579   0.33367166]\n",
      "iter 21000 weight_dist 0.000670867373478 w_curr [ 12.29091793   3.46833345   2.38315035   0.33881494]\n",
      "iter 21500 weight_dist 5.29045700867e-05 w_curr [ 12.37741162   3.49319001   2.40983441   0.3259834 ]\n",
      "iter 22000 weight_dist 7.95893336705e-05 w_curr [ 12.46391014   3.50778869   2.41631495   0.30189804]\n",
      "iter 22500 weight_dist 0.00084424503414 w_curr [ 12.53840547   3.52694346   2.43751995   0.30387755]\n",
      "iter 23000 weight_dist 0.000317482655018 w_curr [ 12.61825598   3.54803049   2.45063364   0.28824622]\n",
      "iter 23500 weight_dist 0.00107257325245 w_curr [ 12.69594304   3.57030098   2.47062603   0.28049198]\n",
      "iter 24000 weight_dist 0.000393242074206 w_curr [ 12.75948125   3.58482588   2.4798575    0.27963467]\n",
      "iter 24500 weight_dist 0.000115015242155 w_curr [ 12.81791313   3.59926999   2.4937036    0.27083282]\n",
      "iter 25000 weight_dist 0.000276227834025 w_curr [ 12.87357542   3.62996153   2.51346239   0.26448524]\n",
      "iter 25500 weight_dist 0.00124595793297 w_curr [ 12.92810948   3.64802774   2.53127948   0.26190154]\n",
      "iter 26000 weight_dist 0.000637701275604 w_curr [ 12.97631913   3.66354493   2.53928468   0.25355253]\n",
      "iter 26500 weight_dist 0.0019470447135 w_curr [ 13.02771933   3.67107824   2.54853094   0.24991102]\n",
      "iter 27000 weight_dist 0.000534421434328 w_curr [ 13.07484304   3.68568712   2.55643929   0.24667443]\n",
      "iter 27500 weight_dist 5.05059321604e-05 w_curr [ 13.12167276   3.69838324   2.55950867   0.23917224]\n",
      "iter 28000 weight_dist 0.000273053369375 w_curr [ 13.16606002   3.70651477   2.56941713   0.22540431]\n",
      "iter 28500 weight_dist 0.000222365772388 w_curr [ 13.21636933   3.7105205    2.57556894   0.21141997]\n",
      "iter 29000 weight_dist 0.000327628857215 w_curr [ 13.25527101   3.72156705   2.58679201   0.20000532]\n",
      "iter 29500 weight_dist 0.00113883844746 w_curr [ 13.2983641    3.72398181   2.59338613   0.19225968]\n",
      "iter 30000 weight_dist 0.000202489712733 w_curr [ 13.33529479   3.72623041   2.60255733   0.18837194]\n",
      "iter 30500 weight_dist 0.000155040906221 w_curr [ 13.36526754   3.73694764   2.60512049   0.18216195]\n",
      "iter 31000 weight_dist 0.000297259309707 w_curr [ 13.39706233   3.75051777   2.61919162   0.17370079]\n",
      "iter 31500 weight_dist 0.000519783620753 w_curr [ 13.42595631   3.75867644   2.62450489   0.17192354]\n",
      "iter 32000 weight_dist 0.000576080501586 w_curr [ 13.45036748   3.76157373   2.62068453   0.16288527]\n",
      "iter 32500 weight_dist 0.000257162066921 w_curr [ 13.48587615   3.75501083   2.62912694   0.15369608]\n",
      "iter 33000 weight_dist 0.000533938890026 w_curr [ 13.51477608   3.75957909   2.64015359   0.14601749]\n",
      "iter 33500 weight_dist 0.000976562678004 w_curr [ 13.54176886   3.76994539   2.64899154   0.13648514]\n",
      "iter 34000 weight_dist 0.000527988738598 w_curr [ 13.56233229   3.77497223   2.65980417   0.13602907]\n",
      "iter 34500 weight_dist 0.00166522009642 w_curr [ 13.58736001   3.79038409   2.66465423   0.13529104]\n",
      "iter 35000 weight_dist 0.000418434837494 w_curr [ 13.6064669    3.79079025   2.670433     0.13706509]\n",
      "iter 35500 weight_dist 0.000284057154957 w_curr [ 13.62731742   3.7955354    2.6791566    0.13000891]\n",
      "iter 36000 weight_dist 0.000298504376347 w_curr [ 13.64165043   3.80403656   2.69239318   0.12830461]\n",
      "iter 36500 weight_dist 0.000446178480018 w_curr [ 13.65758834   3.81100052   2.69034078   0.12169844]\n",
      "iter 37000 weight_dist 7.31653662386e-05 w_curr [ 13.67251551   3.81161006   2.70304022   0.1135568 ]\n",
      "iter 37500 weight_dist 0.00407263558968 w_curr [ 13.69042005   3.81339306   2.70600754   0.1102537 ]\n",
      "iter 38000 weight_dist 0.000401809396616 w_curr [ 13.7063382    3.81960509   2.70233061   0.09940732]\n",
      "iter 38500 weight_dist 0.000431085228295 w_curr [ 13.71526072   3.82330244   2.70597059   0.09836299]\n",
      "iter 39000 weight_dist 7.44000271624e-05 w_curr [ 13.7335863    3.8309082    2.7073964    0.09011065]\n",
      "iter 39500 weight_dist 2.25649885256e-05 w_curr [ 13.75149451   3.83479834   2.70332271   0.07854753]\n",
      "iter 40000 weight_dist 0.00101553558844 w_curr [ 13.77019219   3.83602388   2.70737304   0.08242356]\n",
      "iter 40500 weight_dist 0.00139178731371 w_curr [ 13.77715833   3.83975624   2.70803678   0.08276632]\n",
      "iter 41000 weight_dist 0.000671641629655 w_curr [ 13.79054741   3.85021292   2.710896     0.07636041]\n",
      "iter 41500 weight_dist 0.000533018556151 w_curr [ 13.80179533   3.85173958   2.71772441   0.07013236]\n",
      "iter 42000 weight_dist 0.000625905417976 w_curr [ 13.80972013   3.85560795   2.70933147   0.06223998]\n",
      "iter 42500 weight_dist 0.000553109783046 w_curr [ 13.81802115   3.85851445   2.71626625   0.05868438]\n",
      "iter 43000 weight_dist 0.000187996581848 w_curr [ 13.82764886   3.8574265    2.72231265   0.0548478 ]\n",
      "iter 43500 weight_dist 0.000266844114511 w_curr [ 13.83457803   3.86720488   2.72300242   0.04979437]\n",
      "iter 44000 weight_dist 0.000512455763911 w_curr [ 13.84281114   3.86384301   2.72848513   0.04870541]\n",
      "iter 44500 weight_dist 0.000258112336245 w_curr [ 13.84999592   3.86840454   2.73035927   0.04481702]\n",
      "iter 45000 weight_dist 0.000405765803656 w_curr [ 13.85892631   3.87350924   2.74002138   0.04560412]\n",
      "iter 45500 weight_dist 0.000222658862263 w_curr [ 13.86633774   3.8815014    2.74049549   0.0419829 ]\n",
      "iter 46000 weight_dist 0.000485753242359 w_curr [ 13.86931891   3.88668885   2.74457899   0.04311371]\n",
      "iter 46500 weight_dist 0.000513390904056 w_curr [ 13.87782283   3.88913198   2.75832385   0.04828923]\n",
      "iter 47000 weight_dist 0.000397060801043 w_curr [ 13.88629972   3.89700938   2.7572132    0.04707239]\n",
      "iter 47500 weight_dist 0.000130613814198 w_curr [ 13.89526109   3.89876364   2.76736047   0.05014499]\n",
      "iter 48000 weight_dist 0.000364235078829 w_curr [ 13.90788327   3.89728976   2.77014568   0.03787846]\n",
      "iter 48500 weight_dist 0.000109747222558 w_curr [ 13.91502026   3.89303249   2.76994736   0.03103254]\n",
      "iter 49000 weight_dist 0.000676259778259 w_curr [ 13.91925202   3.89291339   2.76959046   0.02849945]\n",
      "iter 49500 weight_dist 0.000441005039029 w_curr [ 13.92656402   3.89192757   2.77520878   0.03391875]\n",
      "iter 50000 weight_dist 0.000546889536589 w_curr [ 13.93512843   3.89304785   2.76986185   0.02705736]\n",
      "iter 50500 weight_dist 7.17482014613e-05 w_curr [ 13.93523941   3.89499103   2.76966825   0.02274105]\n",
      "iter 51000 weight_dist 4.25413961422e-05 w_curr [ 13.94271697   3.89389572   2.7699519    0.0161618 ]\n",
      "iter 51500 weight_dist 0.000522863620029 w_curr [ 13.94589405   3.89846012   2.77394852   0.01770325]\n",
      "iter 52000 weight_dist 0.000204799002453 w_curr [ 13.94955375   3.90649563   2.77131599   0.01604772]\n",
      "iter 52500 weight_dist 0.00020396871538 w_curr [  1.39507047e+01   3.90277434e+00   2.77231084e+00   9.45588741e-03]\n",
      "iter 53000 weight_dist 0.00111545344911 w_curr [  1.39506156e+01   3.90016215e+00   2.76912556e+00   1.11187637e-02]\n",
      "iter 53500 weight_dist 0.00047020375738 w_curr [ 13.95249294   3.90042691   2.78101953   0.01513765]\n",
      "iter 54000 weight_dist 0.00421598313818 w_curr [ 13.95807694   3.89885166   2.78112395   0.01793695]\n",
      "iter 54500 weight_dist 5.51081363376e-05 w_curr [ 13.9542641    3.8998424    2.78341087   0.01670712]\n",
      "iter 55000 weight_dist 0.000644000571605 w_curr [ 13.95811799   3.89742071   2.7822244    0.01544963]\n",
      "iter 55500 weight_dist 0.000739814392956 w_curr [ 13.96108505   3.88994637   2.78200359   0.01682242]\n",
      "iter 56000 weight_dist 0.0014742874154 w_curr [  1.39658558e+01   3.88648207e+00   2.77702084e+00   1.18111236e-02]\n",
      "iter 56500 weight_dist 0.000674141808552 w_curr [ 13.96627796   3.88646341   2.77853744   0.01442222]\n",
      "iter 57000 weight_dist 0.000288008573065 w_curr [  1.39717602e+01   3.88371239e+00   2.78617058e+00   1.13583797e-02]\n",
      "iter 57500 weight_dist 0.000659773978941 w_curr [ 13.97649286   3.8834544    2.79343697   0.01433265]\n",
      "iter 58000 weight_dist 0.00105277511783 w_curr [  1.39824992e+01   3.88747450e+00   2.79290467e+00   1.37726903e-02]\n",
      "iter 58500 weight_dist 0.000763380069221 w_curr [  1.39824901e+01   3.88873186e+00   2.79755633e+00   1.30840466e-02]\n",
      "iter 59000 weight_dist 0.000297602996301 w_curr [  1.39859253e+01   3.88384105e+00   2.79588726e+00   6.08793651e-03]\n",
      "iter 59500 weight_dist 0.00019829650541 w_curr [  1.39852371e+01   3.88469473e+00   2.79059494e+00  -1.04462678e-03]\n",
      "iter 60000 weight_dist 0.00106169873739 w_curr [  1.39857043e+01   3.88544484e+00   2.79290919e+00  -2.81669704e-03]\n",
      "iter 60500 weight_dist 0.00076056453619 w_curr [  1.39885251e+01   3.87959911e+00   2.79062431e+00  -1.17010176e-03]\n",
      "iter 61000 weight_dist 0.000223304734192 w_curr [  1.39906911e+01   3.87436954e+00   2.79639091e+00  -1.22584396e-03]\n",
      "iter 61500 weight_dist 0.000121437759437 w_curr [  1.39894906e+01   3.87730722e+00   2.78825987e+00  -1.32285378e-03]\n",
      "iter 62000 weight_dist 0.00069188522604 w_curr [  1.39850423e+01   3.88444502e+00   2.78489443e+00  -3.15763548e-03]\n",
      "iter 62500 weight_dist 0.000447063451516 w_curr [  1.39791093e+01   3.88939036e+00   2.78482309e+00  -2.40136589e-03]\n",
      "iter 63000 weight_dist 0.00112699157773 w_curr [  1.39829722e+01   3.88613260e+00   2.78492614e+00   4.87644117e-03]\n",
      "iter 63500 weight_dist 0.000370631399182 w_curr [  1.39899511e+01   3.88279579e+00   2.78315405e+00   5.35213410e-03]\n",
      "iter 64000 weight_dist 1.46910480279e-05 w_curr [  1.39902131e+01   3.88038357e+00   2.78535034e+00   2.54034345e-03]\n",
      "iter 64500 weight_dist 0.00031376113223 w_curr [  1.39951659e+01   3.87847409e+00   2.78457990e+00  -1.45764626e-03]\n",
      "iter 65000 weight_dist 0.000351844546784 w_curr [  1.39979528e+01   3.87610641e+00   2.78784583e+00  -4.70517027e-04]\n",
      "iter 65500 weight_dist 0.000784338501932 w_curr [  1.39942796e+01   3.87936859e+00   2.78245254e+00  -2.40163581e-03]\n",
      "iter 66000 weight_dist 0.00096688643308 w_curr [  1.39946157e+01   3.88439416e+00   2.78033023e+00  -2.72100879e-04]\n",
      "iter 66500 weight_dist 0.000108351146924 w_curr [  1.39938851e+01   3.88918093e+00   2.77802801e+00  -7.87343384e-04]\n",
      "iter 67000 weight_dist 0.000505870125218 w_curr [  1.39987972e+01   3.88656091e+00   2.77571314e+00  -1.66908175e-03]\n",
      "iter 67500 weight_dist 0.000562331504807 w_curr [  1.39988419e+01   3.89036200e+00   2.77908197e+00  -1.12736273e-03]\n",
      "iter 68000 weight_dist 0.00109656306446 w_curr [  1.39976406e+01   3.88545440e+00   2.78138111e+00  -4.33312777e-03]\n",
      "iter 68500 weight_dist 0.000686864504423 w_curr [  1.39963689e+01   3.88131805e+00   2.78684600e+00  -4.08593204e-03]\n",
      "iter 69000 weight_dist 8.21795461538e-06 w_curr [  1.39984063e+01   3.88705731e+00   2.79004405e+00   7.85569784e-03]\n",
      "iter 69500 weight_dist 0.000727020317608 w_curr [  1.39954560e+01   3.88773013e+00   2.77833945e+00   5.75914343e-03]\n",
      "iter 70000 weight_dist 0.000257919423502 w_curr [  1.39972263e+01   3.88584161e+00   2.78537455e+00   4.33247580e-03]\n",
      "iter 70500 weight_dist 0.000564228230031 w_curr [  1.39962464e+01   3.88541152e+00   2.78628907e+00  -5.89584369e-03]\n",
      "iter 71000 weight_dist 0.000238742746958 w_curr [  1.39958090e+01   3.89123302e+00   2.78565960e+00  -5.56292065e-03]\n",
      "iter 71500 weight_dist 0.000692690755139 w_curr [  1.40004024e+01   3.89395804e+00   2.78878054e+00  -1.63037980e-03]\n",
      "iter 72000 weight_dist 7.33786308346e-05 w_curr [  1.39995375e+01   3.90057303e+00   2.78752204e+00  -5.03524435e-03]\n",
      "iter 72500 weight_dist 0.000254885538141 w_curr [  1.39962449e+01   3.91195780e+00   2.78598554e+00  -9.48948080e-03]\n",
      "iter 73000 weight_dist 0.00104324660682 w_curr [  1.40024744e+01   3.90442350e+00   2.78598248e+00  -1.12801899e-02]\n",
      "iter 73500 weight_dist 0.000370751869483 w_curr [  1.40042158e+01   3.90279766e+00   2.79466613e+00  -8.19154793e-03]\n",
      "iter 74000 weight_dist 8.75108319549e-05 w_curr [  1.40021091e+01   3.90729497e+00   2.79275906e+00  -7.79743768e-03]\n",
      "iter 74500 weight_dist 7.30259395592e-05 w_curr [  1.39989891e+01   3.90961781e+00   2.79203241e+00  -9.90780733e-03]\n",
      "iter 75000 weight_dist 0.000653555267685 w_curr [  1.39950166e+01   3.91106860e+00   2.80027506e+00  -2.27017149e-03]\n",
      "iter 75500 weight_dist 0.00211722920913 w_curr [  1.39952416e+01   3.90608270e+00   2.80192194e+00  -9.55816918e-03]\n",
      "iter 76000 weight_dist 0.00209851299533 w_curr [  1.39945082e+01   3.91253866e+00   2.79352797e+00  -1.18320043e-02]\n",
      "iter 76500 weight_dist 7.09731018198e-05 w_curr [  1.39938648e+01   3.91059616e+00   2.79059867e+00  -1.28681741e-02]\n",
      "iter 77000 weight_dist 0.00210304561226 w_curr [  1.39994958e+01   3.90349808e+00   2.78862109e+00  -1.37165143e-02]\n",
      "iter 77500 weight_dist 0.000539436276897 w_curr [ 13.99618376   3.90337664   2.78802931  -0.01772344]\n",
      "iter 78000 weight_dist 0.000567460447084 w_curr [ 14.00290463   3.90397235   2.79158514  -0.01589634]\n",
      "iter 78500 weight_dist 0.000516244662162 w_curr [  1.40065849e+01   3.90836293e+00   2.79743075e+00  -9.15913237e-03]\n",
      "iter 79000 weight_dist 0.000811080398352 w_curr [  1.40078299e+01   3.90568222e+00   2.79852849e+00  -7.36310202e-03]\n",
      "iter 79500 weight_dist 0.000497553894013 w_curr [  1.40129300e+01   3.90870793e+00   2.79425681e+00  -8.32584273e-03]\n",
      "iter 80000 weight_dist 0.00121524134996 w_curr [ 14.01688233   3.90531929   2.79502466  -0.01463177]\n",
      "iter 80500 weight_dist 0.000260239899287 w_curr [  1.40168670e+01   3.90722393e+00   2.79190850e+00  -1.35781490e-02]\n",
      "iter 81000 weight_dist 0.000132132612371 w_curr [ 14.01568064   3.90377388   2.79635098  -0.01848444]\n",
      "iter 81500 weight_dist 0.00074259278912 w_curr [  1.40133760e+01   3.91754637e+00   2.79178207e+00  -1.23211790e-02]\n",
      "iter 82000 weight_dist 0.00208401412744 w_curr [  1.40170791e+01   3.91016387e+00   2.78661091e+00  -6.01592966e-03]\n",
      "iter 82500 weight_dist 0.000407594983094 w_curr [  1.40218055e+01   3.90678899e+00   2.78682279e+00  -5.99910412e-03]\n",
      "iter 83000 weight_dist 0.000765089431396 w_curr [  1.40177350e+01   3.91149377e+00   2.78247971e+00  -4.90381715e-03]\n",
      "iter 83500 weight_dist 0.000219573807765 w_curr [  1.40166291e+01   3.90890494e+00   2.78594913e+00  -4.57333697e-03]\n",
      "iter 84000 weight_dist 0.00085782204862 w_curr [  1.40145037e+01   3.91597002e+00   2.78108085e+00  -6.54200018e-03]\n",
      "iter 84500 weight_dist 8.78928663531e-09 w_curr [  1.40190566e+01   3.91069256e+00   2.78209808e+00  -8.10462217e-03]\n",
      "CPU times: user 13 s, sys: 48.2 ms, total: 13.1 s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X,y,[0.0,0.0,0.0,0.0],eta=1e-2,max_iter=1e5,min_weight_dist=1e-8, seed=42, verbose=True)# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fdfb931c590>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEPCAYAAACHuClZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdfbe05f210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.40190566e+01,   3.91069256e+00,   2.78209808e+00,\n",
       "        -8.10462217e-03])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7844125884067052"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258841\n"
     ]
    }
   ],
   "source": [
    "answer4 = mserror(np.dot(X,stoch_grad_desc_weights),y)# Ваш код здесь\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
